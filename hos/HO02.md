# HO02: Text Normalization & Tokenization
Sobre o texto `Shakespeare.txt`, realizar as seguintes ações em Python:

## Text Normalization
Realizar as normalizações abaixo e gerar um arquivo de saída denominado `ShakespeareNormalized.txt`:

1. lower case reduction
2. accent and diacritic removal
3. canonicalizing of acronyms, currency, date and hyphenated words
4. punctuation removal (except currency and date).
5. special characters removal

## Text Tokenization:
Realizar cada uma das seguintes tokenizações no arquivo de entrada `ShakespeareNormalized.txt` e gerar o arquivo de saída `ShakespeareTokenizedXX.txt`, onde `XX` é o número da tarefa. Por exemplo, o arquivo `ShakespeareTokenized01.txt` é a saída do algoritmo 1 (White Space Tokenization):

1. White Space Tokenization
2. NLTK: Word Tokenizer
3. NLTK: Tree Bank Tokenizer
4. NLTK: Word Punctuation Tokenizer
5. NLTK: Tweet Tokenizer
6. NLTK: MWE Tokenizer
7. TextBlob Word Tokenizer
8. spaCy Tokenizer
9. Gensim Word Tokenizer
10. Keras Tokenization

Teste o funcionamento do código usando o seguinte texto:

```
It's true, Ms. Martha Töpfer! $3.00 on 3/21/2023 in cash for an ice-cream in the U.S. market? :-( #Truth
```

Disponibilizar o código-fonte em sua branch pessoal no repositório git dentro da pasta HO02.
