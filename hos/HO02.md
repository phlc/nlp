# HO02: Text Normalization & Tokenization
Sobre o dataset Shakespeare.txt, realizar em Python as seguintes ações:

## Text Normalization
1. lower case reduction
2. accent and diacritic removal
3. canonicalizing of acronyms, currency, date and hyphenated words
4. punctuation removal (except currency and date.
5. special characters removal

## Text Tokenization:
1. White Space Tokenization
2. NLTK: Word Tokenizer
3. NLTK: Tree Bank Tokenizer
4. NLTK: Word Punctuation Tokenizer
5. NLTK: Tweet Tokenizer
6. NLTK: MWE Tokenizer
7. TextBlob Word Tokenizer
8. spaCy Tokenizer
9. Gensim Word Tokenizer
10. Keras Tokenization

Teste o funcionamento do código usando o seguinte texto:

```
*It's true, Ms. Martha Töpfer! $3.00 on 3/21/2023 in cash for an ice-cream in the U.S. market? :-( #Truth*
```

Disponibilizar o código-fonte em sua branch pessoal no repositório git dentro
da pasta HO02.
